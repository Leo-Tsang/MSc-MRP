{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Logistic Regression & RForests\n",
    "\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Handle Imbalance Data\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import smote_variants as sv\n",
    "\n",
    "#ML ALgorithims\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier, plot_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leotsang/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (28) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Reading our data\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col=0)\n",
    "test = pd.read_csv('test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['player_name', 'school', 'conference', 'GP', 'Min_per', 'ORtg', 'usg',\n",
       "       'eFG', 'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM',\n",
       "       'FTA', 'FT_per', '2PM', '2PA', '2P_per', '3PM', '3PA', '3P_per',\n",
       "       'blk_per', 'stl_per', 'ftr', 'yr', 'ht', 'num', 'porpag', 'adjoe',\n",
       "       'pfr', 'year', 'pid', 'type', 'rec-rk', 'ast/tov', 'rimmade',\n",
       "       'rimmade + rimmiss', 'midmade', 'midmade + midmiss',\n",
       "       'rimmade/(rimmade+rimmiss)', 'midmade/(midmade+mismiss)', 'dunksmade',\n",
       "       'dunksmiss + dunksmade', 'dunksmade/(dunksmade+dunksmiss)', 'pick',\n",
       "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
       "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
       "       'pts', 'pos', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'ht_in',\n",
       "       'drafted', 'yr_cat', 'ATH', 'GP_adj', 'BBIQ'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stats to look at\n",
    "\n",
    "per_stats = ['Min_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FT_per', '2P_per', '3P_per', \n",
    "             'blk_per', 'stl_per', 'GP', 'ht_in', 'yr_cat',  'ATH', 'BBIQ']\n",
    "box_stats = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg','oreb', 'dreb', 'treb',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'FTA', 'FTM', 'ftr',  'ATH', 'BBIQ']\n",
    "adv_stats = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'dreb', 'treb',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'FTA', 'FTM', 'ftr' ,'ATH', 'BBIQ']\n",
    "\n",
    "per_adv = ['Min_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FT_per', '2P_per', '3P_per', \n",
    "             'blk_per', 'stl_per', 'GP', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'ATH', 'BBIQ']\n",
    "\n",
    "all_stats = ['GP', 'Min_per', 'ORtg', 'usg',\n",
    "       'eFG', 'TS_per', 'ORB_per', 'DRB_per', 'AST_per', 'TO_per', 'FTM',\n",
    "       'FTA', 'FT_per', '2PM', '2PA', '2P_per', '3PM', '3PA', '3P_per',\n",
    "       'blk_per', 'stl_per', 'ftr', 'porpag', 'adjoe',\n",
    "       'pfr','year', 'rec-rk', 'ast/tov', \n",
    "       'drtg', 'adrtg', 'dporpag', 'stops', 'bpm', 'obpm', 'dbpm', 'gbpm',\n",
    "       'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', 'ast', 'stl', 'blk',\n",
    "       'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'yr_cat', 'ht_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_stats = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'dreb', 'treb',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'FTA', 'FTM', 'ftr' ,'ATH', 'BBIQ']\n",
    "\n",
    "adv_stats2 = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'dreb', 'treb', 'ftr',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'FTA', 'FTM','ATH']\n",
    "\n",
    "adv_stats3 = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'treb', 'ftr',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'FTA', 'FTM','ATH']\n",
    "\n",
    "adv_stats4 = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'treb', 'ftr',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'FTA', 'FTM','ATH']\n",
    "\n",
    "adv_stats5 = ['GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PM_pg', 'oreb', 'treb', 'ftr',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'FTA', 'FTM','ATH']\n",
    "\n",
    "tests = [adv_stats, adv_stats2, adv_stats3, adv_stats4, adv_stats5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete all missing values\n",
    "train = train.dropna(axis=0, subset=per_stats)\n",
    "train = train.dropna(axis=0, subset=box_stats)\n",
    "train = train.dropna(axis=0, subset=adv_stats)\n",
    "\n",
    "#delete mssing value in test set as well\n",
    "\n",
    "test = test.dropna(axis=0, subset=per_stats)\n",
    "test = test.dropna(axis=0, subset=box_stats)\n",
    "test = test.dropna(axis=0, subset=adv_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set our 2 test-set aside\n",
    "test_2018 = test[test['year']==2018]\n",
    "test_2019 = test[test['year']==2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_3 = pd.concat([train, test_2018])\n",
    "train3 = train_3[(train_3['bpm']>= -0.6) & (train_3['pts']>= 3) & (train_3['ht_in']>= 72)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4247787610619469 recall: 0.47058823529411764 precision: 0.3870967741935484 predictions: 62.0\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "over = SMOTE(sampling_strategy=0.03)\n",
    "under = RandomUnderSampler(sampling_strategy=0.03)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X, y = pipeline.fit_resample(train_3[adv_stats], train_3['drafted'])\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict_proba(test_2019[adv_stats])\n",
    "\n",
    "predictions = [np.round(value[1]) for value in y_pred]\n",
    "\n",
    "#roc_auc = roc_auc_score(test_2019['drafted'], predictions)\n",
    "f1 = f1_score(test_2019['drafted'], predictions)\n",
    "recall = recall_score(test_2019['drafted'], predictions)\n",
    "precision = precision_score(test_2019['drafted'], predictions)\n",
    "print('F1: {} recall: {} precision: {} predictions: {}'.format(f1, recall, precision, sum(predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = []\n",
    "\n",
    "for i in range(0,len(test_2019)):\n",
    "    prob.append(y_pred[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leotsang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/leotsang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_2019['pred_prob'] = prob\n",
    "test_2019['draft_pred'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_stats_res = ['player_name','GP', 'mp', 'pts', '2PA_pg', '2PM_pg', '3PA_pg', '3PM_pg', 'oreb', 'dreb', 'treb',\n",
    "             'ast', 'stl', 'blk', 'ht_in', 'yr_cat', 'bpm', 'obpm', 'dbpm', 'FTA', 'FTM', 'ftr' ,'ATH', 'BBIQ', 'pick', 'drafted', 'draft_pred','pred_prob']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_table = test_2019[adv_stats_res].sort_values('pred_prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_res = res_table[(res_table['pred_prob']>= 0.5) | (res_table['pick']> 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_res.to_excel('results_logreg.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.4285714285714286 recall: 0.4528301886792453 precision: 0.4067796610169492 predictions: 59.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leotsang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/leotsang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=10000)\n",
    "over = SMOTE(sampling_strategy=0.03)\n",
    "under = RandomUnderSampler(sampling_strategy=0.03)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "X, y = pipeline.fit_resample(train_3[adv_stats], train_3['drafted'])\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict_proba(test_2018[adv_stats])\n",
    "\n",
    "predictions = [np.round(value[1]) for value in y_pred]\n",
    "\n",
    "#roc_auc = roc_auc_score(test_2019['drafted'], predictions)\n",
    "f1 = f1_score(test_2018['drafted'], predictions)\n",
    "recall = recall_score(test_2018['drafted'], predictions)\n",
    "precision = precision_score(test_2018['drafted'], predictions)\n",
    "print('F1: {} recall: {} precision: {} predictions: {}'.format(f1, recall, precision, sum(predictions)))\n",
    "\n",
    "prob = []\n",
    "for i in range(0,len(test_2018)):\n",
    "    prob.append(y_pred[i][1])\n",
    "\n",
    "test_2018['pred_prob'] = prob\n",
    "test_2018['draft_pred'] = predictions\n",
    "\n",
    "res_table = test_2018[adv_stats_res].sort_values('pred_prob', ascending=False)\n",
    "res_res = res_table[(res_table['pred_prob']>= 0.5) | (res_table['pick']> 0)]\n",
    "res_res.to_excel('results_logreg_2018.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
